{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Cópia de deteção_anomalia_emissoes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cobridi/detecao-anomalias-emissoes/blob/main/dete%C3%A7%C3%A3o_anomalia_emissoes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R6BPzT8dIRE"
      },
      "source": [
        "# Introdução\n",
        "\n",
        "Este Notebook faz parte do trabalho final do curso BI MASTER Turma 2019.03 do aluno Claudio Bridi, orientado pela Prof. Evelyn.\n",
        "\n",
        "# Objetivo: \n",
        "\n",
        "Criar um algoritmo para detectar anomalias em série temporal de emissões mensais de CO2-equivalente das fontes de uma UEP (Unidade Estacionária de Produção de Óleo e Gás), no período de 2015 a 2019.\n",
        "\n",
        "# Material\n",
        "- Google Colaboratory\n",
        "- Planilha de dados brutos contendo \"nome da instalação\", \"tipo de fonte\", \"código da fonte\", \"Ano\", \"Mês\", \"CO2 emitido\", em formatos csv e excel\n",
        "- Git Hub\n",
        "- Arquivo com código em python da disciplina CONF: deteçãodeanomaliasemseries.ipynb\n",
        "\n",
        "# Aplicabilidade:\n",
        "Este algoritmo poderá ser utilizado na industria de óleo e gás, mais especificamente, e também para empresas que precisem registrar, inventariar, divulgar e trabalhar com dados de emissões de gases de efeito estufa. Para detecção e correção das anomalias em dados, na maioria das vezes inseridos manualmente em sistema ou planilha específica, também costumamente são verificados no olho por algum profissional todos o anos, antes de comporem as informações do inventário e relatório de emissões, divulgado tanto internamente quanto para stakeholders externos. Isto é, por serem muitos dados e de muitas fontes, anomalias podem passar despercebidas, prejudicando a análise de dados, atendimento de compromissos assumidos e perda de credibilidade.\n",
        "\n",
        "# Orientação:\n",
        "Esta ideia surgiu na disciplina de Confiabilidade quando estudamos a detecção de anomalias em séries temporais de dados de precipitação em NY. Pensei em como ponto de partida utilizar o mesmo algorítimo e avançar a partir de então. #\n",
        "\n",
        "# Prazo:\n",
        "Finalizado no GitHub até 30/12/2020.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkUY3H-MN2gK"
      },
      "source": [
        "# Detecção de anomalias em Séries Temporais de Emissões de Gases de Efeito Estufa por equipamentos de uma plataforma de petróleo\n",
        "\n",
        "### Planejamento por etapas:\n",
        "\n",
        "*  Carregar, preparar e analisar dados\n",
        "*  Pré-Processar os dados\n",
        "*  Controle estatístico do processo (CEP) para detectar anomalias*\n",
        "*  Modelos Autorregressivos\n",
        "*  Avaliação dos modelos\n",
        "*  Conclusão Final\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRSjprkrdIRE"
      },
      "source": [
        "## Importando\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5w5PUjeqIAw"
      },
      "source": [
        "%matplotlib inline\r\n",
        "#import warnings\r\n",
        "#warnings.filterwarnings('ignore', category=FutureWarning)\r\n",
        "import sys\r\n",
        "import datetime as dt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import random\r\n",
        "import seaborn as sns\r\n",
        "from scipy import stats\r\n",
        "import statsmodels as ss\r\n",
        "import statsmodels.api as sm\r\n",
        "from statsmodels.tsa.arima_model import ARIMA\r\n",
        "from datetime import datetime\r\n",
        "from dateutil.parser import parse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D37CN0FcdIRI"
      },
      "source": [
        "## Verificando as versões do Python e Bibliotieca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYShu1pkqnA6"
      },
      "source": [
        "packages = [matplotlib, np, pd]\r\n",
        "\r\n",
        "msg = f\"\"\"\r\n",
        "Python Version: {sys.version}\r\n",
        "\r\n",
        "library .      version\r\n",
        "-------        -------\"\"\"\r\n",
        "print(msg)\r\n",
        "\r\n",
        "for package in packages:\r\n",
        "    print(f\"{package.__name__:11}    {package.__version__:>7}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrqzvHXZdIRL"
      },
      "source": [
        "# Seção 1: Carregar, Preparar e Analisar os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI85PjU4q5h1"
      },
      "source": [
        "df_emissions = pd.read_excel('Platco2e2015_2019.xlsx', header=7, index_col=0)\r\n",
        "df_emissions.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlQsqa1bRzHt"
      },
      "source": [
        "Queremos duas coisas: Ter uma nova coluna que indique o ano e mês do registro de emissão (2019-10, por exemplo), para que a série de dados fique na sequência. Posteriormente vamos separar os dataframes por tipo de fonte ou Fonte Emissora, para que cada fonte seja uma série de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhakwou1rWmv"
      },
      "source": [
        "df_emissions['11 - Tipo de Fonte'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kofc2WnDGoZC"
      },
      "source": [
        "df_emissions['11 - Tipo de Fonte'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m7YY7MjGF2Q"
      },
      "source": [
        "df_emissions['14 - Fonte Emissora'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE-cIwzBGVNf"
      },
      "source": [
        "df_emissions['14 - Fonte Emissora'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80RPQzRyHTfz"
      },
      "source": [
        "Como visto na análise acima, a coluna '14 - Fonte Emissora' conta com 24 tipo de fontes. Já a coluna '11 - Tipo de Fonte' conta com 8 tipos. Minha ideia preliminar era realizar a análise de anomalia por Tipo de Fonte, no entanto vi que o mesmo tipo de fonte conta com mais de uma fonte emissora e os dados variam muito. Portanto a Análise deverá ser realizada po Fonte Emissora."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-PjsbAJQX_s"
      },
      "source": [
        "df_emissions.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FQjSTp0E1Yp"
      },
      "source": [
        "A coluna '20 - Mês/Ano' está como tipo 'object' e queremos que a mesma fique com o tipo de data e em ordem crescente para a correta análise da série de dados ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN4W3PVECT1d"
      },
      "source": [
        "Vamos dividir a coluna \"20 - Mês/Ano\" e passar só o valor do mês para uma nova coluna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJoSXJHzdbt9"
      },
      "source": [
        "divisao = df_emissions['20 - Mês/Ano'].str.split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYkKLGXBQwpF"
      },
      "source": [
        "divisao.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iurdsBWiY53F"
      },
      "source": [
        "mes = divisao.str.get(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YoxdonWjpic"
      },
      "source": [
        "df_emissions['Mês'] = mes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-IlJOxbXvLd"
      },
      "source": [
        "df_emissions.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI3e7GShCuho"
      },
      "source": [
        "Agora, vamos substituir os meses do formato com letras para números inteiros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9STRJLOkGpr"
      },
      "source": [
        "df_emissions['Mês'].replace({'JAN':\"01\", \"FEV\":\"02\", 'MAR':'03', 'ABR':'04', 'MAI':'05', 'JUN':'06', 'JUL':'07', 'AGO':'08', 'SET':'09', 'OUT':'10', 'NOV':'11', 'DEZ':'12'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PVx7QjFlz2N"
      },
      "source": [
        "df_emissions.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGT6OMvPC97i"
      },
      "source": [
        "Vamos juntar em uma só coluna o ano e mês em formato \"numérico\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JDdjiWJueGD"
      },
      "source": [
        "df_emissions['Ano-Mes'] = df_emissions['21 - Ano civil'].astype(str).add('-') + df_emissions['Mês']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9G45m0wuyTA"
      },
      "source": [
        "df_emissions.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVXrb6ga11Og"
      },
      "source": [
        "df_emissions.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zOlCojSFiG8"
      },
      "source": [
        "Como a data está em formato de série, tenho que convertê-la para date:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0W7qaG5B9Mv"
      },
      "source": [
        "type(df_emissions['Ano-Mes'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYyxyeCL11kz"
      },
      "source": [
        "df_emissions['Ano-Mes'] = pd.to_datetime(df_emissions['Ano-Mes'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE82CcJDBCv7"
      },
      "source": [
        "df_emissions.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlVQxw2Z2A7a"
      },
      "source": [
        "df_emissions.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2KgoRIoHhTz"
      },
      "source": [
        "Colocando os dados em ordem crescente de data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqcMlASRHH5U"
      },
      "source": [
        "df_emissions = df_emissions.sort_values('Ano-Mes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV8DDCBuHPaP"
      },
      "source": [
        "df_emissions.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfOjI1T9Eb72"
      },
      "source": [
        "Agora, vamos criar um novo dataframe com a primeira Fonte Emissora que vamos analisar: T-Z-1235001, que conta com 60 registros, isto é, registros mensais ao longo dos 5 anos da série histórica.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXxH84NAMhzJ"
      },
      "source": [
        "df_fonte1= df_emissions.loc[df_emissions['14 - Fonte Emissora']=='T-Z-1235001']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlcixsLcNXsV"
      },
      "source": [
        "df_fonte1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiWLEeNuGi9w"
      },
      "source": [
        "Vale a pena aqui observar que a Fonte Emissora T-Z-1235001 representa todos os 60 registros do Tipo de Fonte MEA/DEA, portanto estaremos avaliando todos os registros deste tipo de fonte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QZvGnjuIHm2"
      },
      "source": [
        "Agora, vamos separar apenas as colunas com os datos que precisamos analisar: 'Ano-Mes' e os dados de emissões 'CO2e - AR4 (Mg)'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb1K24cFaua-"
      },
      "source": [
        "df_fonte1_ = pd.DataFrame(df_fonte1, columns=['Ano-Mes','CO2e - AR4 (Mg)'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ea399ycbQdy"
      },
      "source": [
        "df_fonte1_.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86B3h6IVNwEe"
      },
      "source": [
        "Até tentei escoder o coluna de index com o código df_fonte1_.style.hide_index(), no entanto o mesmo parece modificar o dataframe e a leitura do mesmo não ficou igual. Não consegui utilizar df_fonte1_.head(), por exemplo. Aí abandonei esta alternativa e criei um outro arquivo .csv para a leitura dos dados ficarem como no exemplo de precipitações da aula, onde só havia duas colunas: 'tempo' 'registro de precipitação', sem index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlWhVEiTM450"
      },
      "source": [
        "#df_fonte1_teste = df_fonte1_.style.hide_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4I9iP8BNMqZ"
      },
      "source": [
        "#df_fonte1_teste.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hJ0mpb7JKjq"
      },
      "source": [
        "Para ler os dados no modelo proposto precisamos do arquivo no formato .csv e apenas com as colunas de data e emissões. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oRnpDycJj4b"
      },
      "source": [
        "df_fonte1_.to_csv('fonte1.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hsAdK1WPVKh"
      },
      "source": [
        "# Leitura e primeira análise gráfica dos dados "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyfofGobp2oO"
      },
      "source": [
        "newdf_fonte1 = pd.read_csv('fonte1.csv', parse_dates=True, index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UahA4H1dqGnK"
      },
      "source": [
        "newdf_fonte1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa72c_yVJp2h"
      },
      "source": [
        "newdf_fonte1['CO2e - AR4 (Mg)'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FapZQXFxEs54"
      },
      "source": [
        "plt.figure(dpi=120)\r\n",
        "newdf_fonte1.plot(ax=plt.gca())\r\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w80lxF9KTvcN"
      },
      "source": [
        "Pela descrição dos dados bem como pelo gráfico plotado, é possível observar que os dados da fonte emissora 'T-Z-1235001' variam de 2279.143017 a 10384.143120, com média de 8008.698108 e desvio padrão de 2009.786665. Com os dados desta forma, não parece haver alguma anomalia bem como também parece ser muito difícil detectar caso haja."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vZtOdKMVbRG"
      },
      "source": [
        "# Análise de Anomalias 1.1: Gráfico de Controle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGQ9e_egV7X7"
      },
      "source": [
        "Pelas estatísticas resumidas e no gráfico provavelmente as anomalias estarão abaixo da média, que é de 8008.698108; portanto, precisamos apenas de um gráfico de controle unilateral. (Preciso descobrir um gráfico que veja acima e abaixo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzChDRM4WKUS"
      },
      "source": [
        "Como os dados de emissões não podem ser um número negativo, quase todos os valores possíveis acima da média estão no intervalo 8008.698108 <= emissão <= 10384.143120), Que estão quase todos dentro de um desvio padrão (2009.786665) Da média e, portanto, provavelmente não sejam anomalias (mas como dito acima, preciso de um gráfico que pegue acima e abaixo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bImiC0n_Xmg4"
      },
      "source": [
        "Portanto, vamos criar um gráfico de controle unilateral (para baixo que era o único exemplo que tinha)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3tilZYKXnkB"
      },
      "source": [
        "def control_plot(time_series, threshold):\r\n",
        "    '''\r\n",
        "    Creates a one-sided control plot from a time series\r\n",
        "    (that is, plots threshold above the mean but not below)\r\n",
        "    Also, returns list of points that exceed the threshold\r\n",
        "    i.e., points for which the value > mean + threshold*(standard deviation)\r\n",
        "    \r\n",
        "    Args: \r\n",
        "        time_series: (pandas dataframe; index column is date in datetime format and  \r\n",
        "        column 0 is data)\r\n",
        "        threshold: z-score threshold for anomaly detection (float)\r\n",
        "\r\n",
        "    Returns: \r\n",
        "        Control plot of time_series    \r\n",
        "        anomalies: anomalies that exceed threshold (pandas dataframe)\r\n",
        "    ''' \r\n",
        "    \r\n",
        "    mean_= time_series.iloc[:,0].mean()\r\n",
        "    stdev_= time_series.iloc[:,0].std()\r\n",
        "    cutoff = mean_+threshold*stdev_\r\n",
        "    plt.figure(dpi=140)\r\n",
        "    time_series.plot(ax=plt.gca())\r\n",
        "    plt.axhline(y=mean_, color='g', linestyle='--', label='mean')\r\n",
        "    # Use threshold to plot line at threshold*stdev_ times away from the mean\r\n",
        "    plt.axhline(y=cutoff, color='r', linestyle=':', label='threshold')\r\n",
        "    plt.legend(loc='best')\r\n",
        "    plt.title('Fonte1')\r\n",
        "    plt.ylabel('Emissões CO2eq')\r\n",
        "    \r\n",
        "    # Create dataframe of anomalies that exceed the cutoff\r\n",
        "    anomalies = time_series[time_series.values > cutoff]\r\n",
        "    return anomalies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcB_JTQ1ZK8H"
      },
      "source": [
        "Defina um limite de 3 desvios padrão e plote os resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVSOyWwQZLeX"
      },
      "source": [
        "anomaly_fonte1 = control_plot(newdf_fonte1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNxumjVItq28"
      },
      "source": [
        "Pelo gráfico gerado, não foi detectada nenhuma anomalia na Fonte 1 = T-Z-1235001. No entanto, como já indicado o mais provável é que a anomalia estivesse abaixo da média e não acima. Aqui que eu precisaria de uma ajudinha do orientador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24Y5AktpZUcH"
      },
      "source": [
        "print(anomaly_fonte1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPf94ebNu-AI"
      },
      "source": [
        "# Análise de Anomalias 1.2: Soma acumulada (CUSUM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_umo8qbvFfD"
      },
      "source": [
        "def cusum(data, mean, shift, threshold):\r\n",
        "    '''\r\n",
        "   as somas cumulativas alta e baixa e use-as para detecção de anomalias.\r\n",
        "     Uma anomalia é relatada se as somas cumulativas estiverem além de um determinado limite.\r\n",
        "    \r\n",
        "     Args:\r\n",
        "         data: (uma série temporal como pandas dataframe; a coluna do índice é a data no formato datetime e\r\n",
        "         coluna 0 são dados)\r\n",
        "         mean: média dos dados ou outra média (flutuante)\r\n",
        "         mudança: mudança normal nos dados; o desvio padrão é recomendado (flutuante)\r\n",
        "         threshold: limite para classificar o ponto como anomalia (float)\r\n",
        "\r\n",
        "     Devoluções:\r\n",
        "         cusum: as somas cumulativas alta e baixa juntas Calcular com os dados (pandas dataframe)\r\n",
        "         anomalias: anomalias acima e abaixo do limite (pandas dataframe)\r\n",
        "    ''' \r\n",
        "    high_sum = 0.0\r\n",
        "    low_sum = 0.0\r\n",
        "    anomalies = [] \r\n",
        "    high_sum_final = []\r\n",
        "    low_sum_final = []\r\n",
        "    index_names = data.index\r\n",
        "    data_values = data.values\r\n",
        "    for index, item in enumerate(data_values):\r\n",
        "        high_sum = max(0, high_sum + item - mean - shift)\r\n",
        "        low_sum = min(0, low_sum + item - mean + shift)\r\n",
        "        high_sum_final.append(high_sum)\r\n",
        "        low_sum_final.append(low_sum)\r\n",
        "        if high_sum > threshold or low_sum < -threshold:\r\n",
        "            anomalies.append((index_names[index], item.tolist()))\r\n",
        "    cusum = data\r\n",
        "    cusum = cusum.assign(High_Cusum=high_sum_final, Low_Cusum=low_sum_final)\r\n",
        "    return cusum, anomalies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXs3VXjHveJR"
      },
      "source": [
        "def cusum_plot(time_series, threshold):\r\n",
        "    '''\r\n",
        "    Plote as somas cumulativas alta e baixa e use-as para detecção de anomalias.\r\n",
        "     Uma anomalia é relatada se as somas cumulativas estiverem além de um determinado limite.\r\n",
        "    \r\n",
        "     Args:\r\n",
        "         time_series: (uma série temporal como pandas dataframe; a coluna de índice é date\r\n",
        "         no formato datetime e a coluna 0 é data)\r\n",
        "         threshold: limite para classificar o ponto como anomalia (float)\r\n",
        "\r\n",
        "     Devoluções:\r\n",
        "         Uma plotagem dos dados com a soma acumulada alta.\r\n",
        "         cusum_results: as somas cumulativas alta e baixa, juntamente com dados\r\n",
        "         e quaisquer anomalias acima e abaixo do limite (quadro de dados do pandas;\r\n",
        "         da função cumsum)\r\n",
        "    ''' \r\n",
        "    # Use a média e o desvio padrão de toda a série temporal\r\n",
        "     # para calcular somas cumulativas\r\n",
        "    mean_= time_series.iloc[:,0].mean()\r\n",
        "    stdev_= time_series.iloc[:,0].std()\r\n",
        "    \r\n",
        "    # definir limiar em termos de desvio padrão\r\n",
        "    cusum_results = cusum(time_series, mean_, stdev_, threshold*stdev_)\r\n",
        "    ax=time_series.plot()\r\n",
        "    ax.axhline(y=mean_, color='g', linestyle='--',label='average')\r\n",
        "    ax.axhline(y=mean_+threshold*stdev_, color='r', linestyle='--',label='High threshold')\r\n",
        "    ax.axhline(y=mean_-threshold*stdev_, color='r', linestyle='--',label='Low threshold')\r\n",
        "    # Use threshold to plot line at threshold*stdev_ times away from the mean\r\n",
        "    ax.scatter(x=cusum_results[0].index, y=cusum_results[0]['Low_Cusum'], \r\n",
        "             color='k', linestyle=':',label='Low Cusum')\r\n",
        "    ax.scatter(x=cusum_results[0].index, y=cusum_results[0]['High_Cusum'], \r\n",
        "             color='y', linestyle=':',label='High Cusum')                 \r\n",
        "    plt.legend(loc='lower right')\r\n",
        "    plt.title('Fonte 1 Emissions - CUSUM')\r\n",
        "    plt.ylabel('CO2 Emissions')\r\n",
        "    plt.gcf().set_size_inches(8,6)\r\n",
        "    plt.show()\r\n",
        "    return cusum_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKC4_4stzeEn"
      },
      "source": [
        "Escolha do limiar: para o gráfico de controle, usamos 3 vezes o desvio padrão. Observe que o limite equivalente para CUSUM é * threshold * = 2, pois CUSUM inclui o * shift * (que escolhemos ser um desvio padrão) em seu cálculo da soma acumulada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJuOSspozjJF"
      },
      "source": [
        "anomaly_fonte1_cusum = cusum_plot(newdf_fonte1, 2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7zHkJjkKV8o"
      },
      "source": [
        "Observe que LOW CUSUM parece detectar maiores anomalias. O resultado reflete a diferença nos algoritmos de CUSUM e Tabela de Controle. A tabela de controle está procurando pontos únicos e anômalos. CUSUM é sensível a alterações no comportamento dos dados. Como resultado, sinaliza pontos como anômalos até que o comportamento da série temporal retorne ao normal.\r\n",
        "\r\n",
        "De fato, CUSUM é usado para detecção de pontos de mudança: encontrar quando a distribuição subjacente da série temporal mudou."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d08nBymGM04o"
      },
      "source": [
        "print(anomaly_fonte1_cusum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jItUk8ctRrSk"
      },
      "source": [
        "Não consegui imprimir apenas os dados que apresentaram apenas anomalias. No gráfico da aula o professo também só teve o dado visual. Outra dificuldade não solucionada foi na plotagem do CUSUM em cima do gráfico de emissões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LWkF3E9SLDl"
      },
      "source": [
        "# Análise 1.3: modelos autorregressivos\r\n",
        "\r\n",
        "Nos dois métodos anteriores, realizamos a análise no modo offline - tínhamos todos os dados de interesse em mãos. Como resultado, ao examinar um determinado ponto, poderíamos usar o passado e o futuro (com relação a esse ponto) para calcular estatísticas como a média e o desvio padrão.\r\n",
        "\r\n",
        "Modelos autorregressivos são comumente usados para detecção de anomalias em fluxo. Para analisar séries temporais no modo de streaming - ou seja, à medida que os dados se tornam disponíveis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0VIP3MWVxMp"
      },
      "source": [
        "Como linha de base para o modelo de regressão automática, podemos verificar o que um gráfico de controle revela como anomalias. Em contraste com o exemplo da precipitação, aqui podemos ter anomalias em ambos os lados da média, portanto modificamos * control_plot * para se tornar um gráfico de controle completo de dois lados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdL8QfRnS0mo"
      },
      "source": [
        "def control_plot_full(time_series, threshold):\r\n",
        "    '''\r\n",
        "    Cria um gráfico de controle frente e verso de uma série temporal\r\n",
        "     (limiar de plotagem acima e abaixo da média)\r\n",
        "     Além disso, retorna a lista de pontos que excedem o limite\r\n",
        "     ou seja, pontos para os quais o valor> média + limite * (desvio padrão)\r\n",
        "     e valor <média - limiar * (desvio padrão)\r\n",
        "    \r\n",
        "     Args:\r\n",
        "         time_series: (pandas dataframe; a coluna de índice é a data no formato datetime e\r\n",
        "         coluna 0 são dados)\r\n",
        "         threshold: limite para detecção de anomalias (float)\r\n",
        "\r\n",
        "     Devoluções:\r\n",
        "         Gráfico de controle de time_series\r\n",
        "         anomalias: anomalias que excedem o limite (pandas dataframe)\r\n",
        "    ''' \r\n",
        "    \r\n",
        "    mean_= time_series.iloc[:, 0].mean()\r\n",
        "    stdev_= time_series.iloc[:, 0].std()\r\n",
        "    time_series.plot()\r\n",
        "    plt.axhline(y=mean_, color='g', linestyle='--',label='average')\r\n",
        "    # Use threshold to plot line at threshold*stdev_ times away from the mean\r\n",
        "    plt.axhline(y=mean_+threshold*stdev_, color='r', linestyle=':', label='high threshold')\r\n",
        "    plt.axhline(y=mean_-threshold*stdev_, color='m', linestyle=':', label='low threshold')\r\n",
        "    plt.legend(loc='upper right')\r\n",
        "    plt.title('Fonte 1 Emissions')\r\n",
        "    plt.ylabel('CO2eq Emissions')\r\n",
        "    plt.gcf().set_size_inches(8,6)\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "    # Create dataframe of anomalies that exceed the threshold\r\n",
        "    anomaly_mask = (np.abs(time_series.values - mean_) > threshold*stdev_)\r\n",
        "    anomalies = time_series[anomaly_mask]\r\n",
        "    return anomalies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOq_GpPcTbak"
      },
      "source": [
        "control_plot_full(newdf_fonte1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSQmuEo3WCpA"
      },
      "source": [
        "Somente pelo resultado do gráfico não encontramos nenhuma anomalia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w-nl6pXTxlE"
      },
      "source": [
        "print(newdf_fonte1.index.inferred_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT7qA_2vT--S"
      },
      "source": [
        "O print acima serviu apenas para identificar a frequência dos registros: Frequência mensal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igMeXXsxT-U4"
      },
      "source": [
        "newdf_fonte1.index.freq=newdf_fonte1.index.inferred_freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwUVjbWKUKQg"
      },
      "source": [
        "efonte1_sar=ARIMA(newdf_fonte1, order=(1,1,4)).fit()\r\n",
        "\r\n",
        "efonte1_sar.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hIXcjIaWRmM"
      },
      "source": [
        "Como no exemplo de aula, não discutiremos as estatísticas relatadas, exceto para dizer que ela inclui o desvio padrão dos resíduos (59.586\t), que usaremos posteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsp3K_EoWqJQ"
      },
      "source": [
        "Verificamos os diagnósticos para verificar se as premissas subjacentes ao modelo são atendidas e também para obter informações adicionais sobre a qualidade do ajuste. Isso é feito usando um gráfico Q-Q (verificando se os resíduos seguem uma distribuição normal), investigando os resíduos por padrões temporais e plotando um histograma dos resíduos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ1_RZKDUgpF"
      },
      "source": [
        "# Get the predicted standard deviation. This is the 6.516 we saw earlier\r\n",
        "sigma_pred = efonte1_sar.resid.std()\r\n",
        "# Calculate the standardized residuals from the (regular) residuals\r\n",
        "efonte1_std_resid = efonte1_sar.resid/sigma_pred\r\n",
        "\r\n",
        "plt.title('Patterns in residual')\r\n",
        "plt.plot(efonte1_std_resid);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj4oQBrEUxPw"
      },
      "source": [
        "fig = plt.figure(figsize=(12,6))\r\n",
        "ax = plt.subplot(121)\r\n",
        "plt.title('Distribution of residuals')\r\n",
        "sns.distplot(efonte1_std_resid.values, bins=50, ax=ax);\r\n",
        "stats.probplot(efonte1_std_resid.values, dist='norm', sparams=(2.5,), plot=plt.subplot(122));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_jZ9RlqW5Dy"
      },
      "source": [
        "Para detecção de anomalias, focamos no gráfico superior: resíduos padronizados. O residual padronizado é o residual (a diferença entre o valor observado e o valor previsto) dividido pelo desvio padrão previsto (a raiz quadrada da variação prevista mencionada acima). É uma versão mais sofisticada do z-score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXG3cHD-W_H9"
      },
      "source": [
        "Uma regra prática para detectar anomalias com resíduos padronizados: anomalias são pontos para os quais a magnitude dos resíduos padronizados é maior que 4. Vamos encontrar esses pontos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kegsv1MSVF4a"
      },
      "source": [
        "# Reportar as anomalias\r\n",
        "anomaly_mask = np.abs(efonte1_std_resid) > 4\r\n",
        "efonte1_anomalies = efonte1_std_resid[anomaly_mask]\r\n",
        "print(efonte1_anomalies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqT1WWt6W9q_"
      },
      "source": [
        "Nosso modelo encontrou como anomalia o dado de 2017-07-01."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbsK7JIcXfpj"
      },
      "source": [
        "newdf_fonte1.iloc[24:36]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4AJzhUBawHu"
      },
      "source": [
        "Analisando os dados de 2017, é possível observar que o dado de '2017-07-01' teve um variação bastante abrupta em relação aos meses anteriores e subsequentes, por isso o modelo o detectou como anômalo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkvH9u_9ap33"
      },
      "source": [
        "\r\n",
        "O próximo passo seria variar os parâmetros do modelo de autorregressão e verificar a robustez dessas descobertas, mas como isso pertence ao reino da análise de série temporal, vamos parar por aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHYL7TltXk5x"
      },
      "source": [
        "# Aplicar os modelos para uma outra fonte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJKur0G0dxaw"
      },
      "source": [
        "Vamos agora valiar outra fonte: TOCHA HP/LP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCJVPprhXtZ2"
      },
      "source": [
        "df_fonte2 = df_emissions.loc[df_emissions['14 - Fonte Emissora']=='TOCHA HP/LP']\r\n",
        "df_fonte2['CO2e - AR4 (Mg)'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q2cX2Ppd2Ew"
      },
      "source": [
        "Esta fonte conta com 50 registros, média de 7484.996844, mínimo de 2635.808233 e máximo de 14950.602733."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5eY2_-KfJRa"
      },
      "source": [
        "df_fonte2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1ndNJWAemx7"
      },
      "source": [
        "Agora, vamos separar apenas as colunas com os datos que precisamos analisar: 'Ano-Mes' e os dados de emissões 'CO2e - AR4 (Mg)'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdFLaHY-emx7"
      },
      "source": [
        "df_fonte2_ = pd.DataFrame(df_fonte2, columns=['Ano-Mes','CO2e - AR4 (Mg)'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drAXRUwmemx7"
      },
      "source": [
        "df_fonte2_.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGnT_1F0emx8"
      },
      "source": [
        "Para ler os dados no modelo proposto precisamos do arquivo no formato .csv e apenas com as colunas de data e emissões. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvqIFfVJemx9"
      },
      "source": [
        "df_fonte2_.to_csv('fonte2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydml02X1emx9"
      },
      "source": [
        "# Leitura e primeira análise gráfica dos dados "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU5pqH3Uemx9"
      },
      "source": [
        "newdf_fonte2 = pd.read_csv('fonte2.csv', parse_dates=True, index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBHsalJTemx9"
      },
      "source": [
        "newdf_fonte2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si0i26tSemx-"
      },
      "source": [
        "plt.figure(dpi=120)\r\n",
        "newdf_fonte2.plot(ax=plt.gca())\r\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SARZWmPiemx-"
      },
      "source": [
        "Pelo gráfico plotado, é possível observar que os dados da fonte emissora ''TOCHA HP/LP' variam bastante entre os valores mínimos e máximos. Com os dados desta forma, não parece haver alguma anomalia bem como também parece ser muito difícil detectar caso haja. Vamos ver se os modelos identificam algo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrjaPLAJhO30"
      },
      "source": [
        "# Análise de Anomalias 2.1: Gráfico de Controle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTLKetcUhO4D"
      },
      "source": [
        "Pelas estatísticas resumidas e no gráfico é difícil presumir se as anomalias estarão acima ou abaixo da média, que é de 7484.996844, com mínimo de 2635.808233 e máximo de 14950.602733. Portanto, precisamos  descobrir um gráfico que veja acima e abaixo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86TSQJiJhO4E"
      },
      "source": [
        "Portanto, vamos criar um gráfico de controle unilateral (para baixo que era o único exemplo que tinha)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grbvHk6FhO4E"
      },
      "source": [
        "def control_plot(time_series, threshold):\r\n",
        "    '''\r\n",
        "    Creates a one-sided control plot from a time series\r\n",
        "    (that is, plots threshold above the mean but not below)\r\n",
        "    Also, returns list of points that exceed the threshold\r\n",
        "    i.e., points for which the value > mean + threshold*(standard deviation)\r\n",
        "    \r\n",
        "    Args: \r\n",
        "        time_series: (pandas dataframe; index column is date in datetime format and  \r\n",
        "        column 0 is data)\r\n",
        "        threshold: z-score threshold for anomaly detection (float)\r\n",
        "\r\n",
        "    Returns: \r\n",
        "        Control plot of time_series    \r\n",
        "        anomalies: anomalies that exceed threshold (pandas dataframe)\r\n",
        "    ''' \r\n",
        "    \r\n",
        "    mean_= time_series.iloc[:,0].mean()\r\n",
        "    stdev_= time_series.iloc[:,0].std()\r\n",
        "    cutoff = mean_+threshold*stdev_\r\n",
        "    plt.figure(dpi=140)\r\n",
        "    time_series.plot(ax=plt.gca())\r\n",
        "    plt.axhline(y=mean_, color='g', linestyle='--', label='mean')\r\n",
        "    # Use threshold to plot line at threshold*stdev_ times away from the mean\r\n",
        "    plt.axhline(y=cutoff, color='r', linestyle=':', label='threshold')\r\n",
        "    plt.legend(loc='best')\r\n",
        "    plt.title('Fonte2')\r\n",
        "    plt.ylabel('Emissões CO2eq')\r\n",
        "    \r\n",
        "    # Create dataframe of anomalies that exceed the cutoff\r\n",
        "    anomalies = time_series[time_series.values > cutoff]\r\n",
        "    return anomalies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOjVNXx2hO4F"
      },
      "source": [
        "Defina um limite de 3 desvios padrão e plote os resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1mvDQWChO4G"
      },
      "source": [
        "anomaly_fonte2 = control_plot(newdf_fonte2, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uCAOlWxhO4I"
      },
      "source": [
        "Pelo gráfico gerado, não foi detectada nenhuma anomalia na Fonte 2 = 'TOCHA HP/LP'. No entanto, como já indicado o precisávamos também avaliar para a parte de baixo da média dos dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_ZmfeRphO4I"
      },
      "source": [
        "print(anomaly_fonte2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrGZNDWzhO4J"
      },
      "source": [
        "# Análise de Anomalias 2.2: Soma acumulada (CUSUM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zzj8mO0hO4K"
      },
      "source": [
        "def cusum_plot(time_series, threshold):\r\n",
        "    '''\r\n",
        "    Plote as somas cumulativas alta e baixa e use-as para detecção de anomalias.\r\n",
        "     Uma anomalia é relatada se as somas cumulativas estiverem além de um determinado limite.\r\n",
        "    \r\n",
        "     Args:\r\n",
        "         time_series: (uma série temporal como pandas dataframe; a coluna de índice é date\r\n",
        "         no formato datetime e a coluna 0 é data)\r\n",
        "         threshold: limite para classificar o ponto como anomalia (float)\r\n",
        "\r\n",
        "     Devoluções:\r\n",
        "         Uma plotagem dos dados com a soma acumulada alta.\r\n",
        "         cusum_results: as somas cumulativas alta e baixa, juntamente com dados\r\n",
        "         e quaisquer anomalias acima e abaixo do limite (quadro de dados do pandas;\r\n",
        "         da função cumsum)\r\n",
        "    ''' \r\n",
        "    # Use a média e o desvio padrão de toda a série temporal\r\n",
        "     # para calcular somas cumulativas\r\n",
        "    mean_= time_series.iloc[:,0].mean()\r\n",
        "    stdev_= time_series.iloc[:,0].std()\r\n",
        "    \r\n",
        "    # definir limiar em termos de desvio padrão\r\n",
        "    cusum_results = cusum(time_series, mean_, stdev_, threshold*stdev_)\r\n",
        "    ax=time_series.plot()\r\n",
        "    ax.axhline(y=mean_, color='g', linestyle='--',label='average')\r\n",
        "    ax.axhline(y=mean_+threshold*stdev_, color='r', linestyle='--',label='High threshold')\r\n",
        "    ax.axhline(y=mean_-threshold*stdev_, color='r', linestyle='--',label='Low threshold')\r\n",
        "    # Use threshold to plot line at threshold*stdev_ times away from the mean\r\n",
        "    ax.scatter(x=cusum_results[0].index, y=cusum_results[0]['Low_Cusum'], \r\n",
        "             color='k', linestyle=':',label='Low Cusum')\r\n",
        "    ax.scatter(x=cusum_results[0].index, y=cusum_results[0]['High_Cusum'], \r\n",
        "             color='y', linestyle=':',label='High Cusum')                 \r\n",
        "    plt.legend(loc='lower right')\r\n",
        "    plt.title('Fonte 2 Emissions - CUSUM')\r\n",
        "    plt.ylabel('CO2 Emissions')\r\n",
        "    plt.gcf().set_size_inches(8,6)\r\n",
        "    plt.show()\r\n",
        "    return cusum_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUU2NtULhO4L"
      },
      "source": [
        "Escolha do limiar: para o gráfico de controle, usamos 3 vezes o desvio padrão. Observe que o limite equivalente para CUSUM é * threshold * = 2, pois CUSUM inclui o * shift * (que escolhemos ser um desvio padrão) em seu cálculo da soma acumulada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJLLipYEhO4L"
      },
      "source": [
        "anomaly_fonte2_cusum = cusum_plot(newdf_fonte2, 2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3yWP2MfhO4M"
      },
      "source": [
        "Observe que HIGH CUSUM parece detectar maiores anomalias. O resultado reflete a diferença nos algoritmos de CUSUM e Tabela de Controle. A tabela de controle está procurando pontos únicos e anômalos. CUSUM é sensível a alterações no comportamento dos dados. Como resultado, sinaliza pontos como anômalos até que o comportamento da série temporal retorne ao normal.\r\n",
        "\r\n",
        "De fato, CUSUM é usado para detecção de pontos de mudança: encontrar quando a distribuição subjacente da série temporal mudou."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y-MYVuJhO4N"
      },
      "source": [
        "print(anomaly_fonte2_cusum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIo1JAyAhO4N"
      },
      "source": [
        "Não consegui imprimir apenas os dados que apresentaram apenas anomalias. No gráfico da aula o professo também só teve o dado visual. Outra dificuldade não solucionada foi na plotagem do CUSUM em cima do gráfico de emissões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlytyr67hO4P"
      },
      "source": [
        "# Análise 2.3: modelos autorregressivos\r\n",
        "\r\n",
        "Nos dois métodos anteriores, realizamos a análise no modo offline - tínhamos todos os dados de interesse em mãos. Como resultado, ao examinar um determinado ponto, poderíamos usar o passado e o futuro (com relação a esse ponto) para calcular estatísticas como a média e o desvio padrão.\r\n",
        "\r\n",
        "Modelos autorregressivos são comumente usados para detecção de anomalias em fluxo. Para analisar séries temporais no modo de streaming - ou seja, à medida que os dados se tornam disponíveis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgkzpQvAhO4P"
      },
      "source": [
        "Como linha de base para o modelo de regressão automática, podemos verificar o que um gráfico de controle revela como anomalias. Em contraste com o exemplo da precipitação, aqui podemos ter anomalias em ambos os lados da média, portanto modificamos * control_plot * para se tornar um gráfico de controle completo de dois lados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXfhmNwxhO4Q"
      },
      "source": [
        "def control_plot_full(time_series, threshold):\r\n",
        "    '''\r\n",
        "    Cria um gráfico de controle frente e verso de uma série temporal\r\n",
        "     (limiar de plotagem acima e abaixo da média)\r\n",
        "     Além disso, retorna a lista de pontos que excedem o limite\r\n",
        "     ou seja, pontos para os quais o valor> média + limite * (desvio padrão)\r\n",
        "     e valor <média - limiar * (desvio padrão)\r\n",
        "    \r\n",
        "     Args:\r\n",
        "         time_series: (pandas dataframe; a coluna de índice é a data no formato datetime e\r\n",
        "         coluna 0 são dados)\r\n",
        "         threshold: limite para detecção de anomalias (float)\r\n",
        "\r\n",
        "     Devoluções:\r\n",
        "         Gráfico de controle de time_series\r\n",
        "         anomalias: anomalias que excedem o limite (pandas dataframe)\r\n",
        "    ''' \r\n",
        "    \r\n",
        "    mean_= time_series.iloc[:, 0].mean()\r\n",
        "    stdev_= time_series.iloc[:, 0].std()\r\n",
        "    time_series.plot()\r\n",
        "    plt.axhline(y=mean_, color='g', linestyle='--',label='average')\r\n",
        "    # Use threshold to plot line at threshold*stdev_ times away from the mean\r\n",
        "    plt.axhline(y=mean_+threshold*stdev_, color='r', linestyle=':', label='high threshold')\r\n",
        "    plt.axhline(y=mean_-threshold*stdev_, color='m', linestyle=':', label='low threshold')\r\n",
        "    plt.legend(loc='upper right')\r\n",
        "    plt.title('Fonte 2 Emissions')\r\n",
        "    plt.ylabel('CO2eq Emissions')\r\n",
        "    plt.gcf().set_size_inches(8,6)\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "    # Create dataframe of anomalies that exceed the threshold\r\n",
        "    anomaly_mask = (np.abs(time_series.values - mean_) > threshold*stdev_)\r\n",
        "    anomalies = time_series[anomaly_mask]\r\n",
        "    return anomalies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5oVos13hO4R"
      },
      "source": [
        "control_plot_full(newdf_fonte2, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BKkzCMwhO4S"
      },
      "source": [
        "Somente pelo resultado do gráfico não encontramos nenhuma anomalia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD5ahe9A0OeJ"
      },
      "source": [
        "Observem que o low threshold não deveria ficar abaixo de 0. Todo dado abaixo de 0 deveria ser considerado uma anomalia, portanto o low threshold deve ser > 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrQG-e2uhO4S"
      },
      "source": [
        "print(newdf_fonte2.index.inferred_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ5ArnNBhO4T"
      },
      "source": [
        "O print acima serviu apenas para identificar a frequência dos registros: Frequência mensal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOJtspfWhO4T"
      },
      "source": [
        "newdf_fonte2.index.freq=newdf_fonte2.index.inferred_freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHxc9TAnkv7S"
      },
      "source": [
        "Para a análise a seguir, tive que alterar a ordem de 1,1,4 para 1,1,2. Não entendi muito bem o que fiz, mas assim não deu mais erro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGxESR0FhO4T"
      },
      "source": [
        "efonte2_sar=ARIMA(newdf_fonte2, order=(1,1,2)).fit()\r\n",
        "\r\n",
        "efonte2_sar.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7ZmUIhthO4U"
      },
      "source": [
        "Como no exemplo de aula, não discutiremos as estatísticas relatadas, exceto para dizer que ela inclui o desvio padrão dos resíduos (34.036\t), que usaremos posteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoXWJvM4hO4U"
      },
      "source": [
        "Verificamos os diagnósticos para verificar se as premissas subjacentes ao modelo são atendidas e também para obter informações adicionais sobre a qualidade do ajuste. Isso é feito usando um gráfico Q-Q (verificando se os resíduos seguem uma distribuição normal), investigando os resíduos por padrões temporais e plotando um histograma dos resíduos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vt3khAyhO4V"
      },
      "source": [
        "# Get the predicted standard deviation. This is the 6.516 we saw earlier\r\n",
        "sigma_pred = efonte2_sar.resid.std()\r\n",
        "# Calculate the standardized residuals from the (regular) residuals\r\n",
        "efonte2_std_resid = efonte2_sar.resid/sigma_pred\r\n",
        "\r\n",
        "plt.title('Patterns in residual')\r\n",
        "plt.plot(efonte2_std_resid);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9pgYJjphO4V"
      },
      "source": [
        "fig = plt.figure(figsize=(12,6))\r\n",
        "ax = plt.subplot(121)\r\n",
        "plt.title('Distribution of residuals')\r\n",
        "sns.distplot(efonte2_std_resid.values, bins=50, ax=ax);\r\n",
        "stats.probplot(efonte2_std_resid.values, dist='norm', sparams=(2.5,), plot=plt.subplot(122));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNXT5rEOhO4V"
      },
      "source": [
        "Para detecção de anomalias, focamos no gráfico superior: resíduos padronizados. O residual padronizado é o residual (a diferença entre o valor observado e o valor previsto) dividido pelo desvio padrão previsto (a raiz quadrada da variação prevista mencionada acima). É uma versão mais sofisticada do z-score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGb1ZaLjhO4V"
      },
      "source": [
        "Uma regra prática para detectar anomalias com resíduos padronizados: anomalias são pontos para os quais a magnitude dos resíduos padronizados é maior que 4. Vamos encontrar esses pontos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qndH8uG0hO4W"
      },
      "source": [
        "# Reportar as anomalias\r\n",
        "anomaly_mask = np.abs(efonte2_std_resid) > 4\r\n",
        "efonte2_anomalies = efonte2_std_resid[anomaly_mask]\r\n",
        "print(efonte2_anomalies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAAVcgAmhO4W"
      },
      "source": [
        "Nosso modelo não encontrou anomalias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7SJN9fMXzbp"
      },
      "source": [
        "# Alterar os dados de uma fonte para ver se o modelo pega."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11zTfQsFl-t1"
      },
      "source": [
        "Agora, vou pegar o arquivo fonte2.csv e alterar manualmente dois dados de dois meses da seguinte forma:\r\n",
        "\r\n",
        "2016-05-01 de 10882.292785568461 para 20882.292785568461\r\n",
        "\r\n",
        "e\r\n",
        "\r\n",
        "2018-05-01 de 4153.738730935139 para 0153.738730935139\r\n",
        "\r\n",
        "que representariam \"erros de digitação\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16hXprspqy6p"
      },
      "source": [
        "Aí vamos aplicar novamente os 3 modelos e ver se detecta estes dados anômalos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bKoaqZIrXNm"
      },
      "source": [
        "## Leitura e primeira análise gráfica dos dados "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKiJ1x3zrXNx"
      },
      "source": [
        "newdf_fonte2_teste = pd.read_csv('fonte2_teste.csv', parse_dates=True, index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghy6CKmarXNx"
      },
      "source": [
        "newdf_fonte2_teste"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7jCwlpXtg_O"
      },
      "source": [
        "newdf_fonte2_teste['CO2e - AR4 (Mg)'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZQq5v4SrXNy"
      },
      "source": [
        "plt.figure(dpi=120)\r\n",
        "newdf_fonte2_teste.plot(ax=plt.gca())\r\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqfuePAgrXNz"
      },
      "source": [
        "Pelo gráfico plotado, é possível observar que os dados da fonte emissora ''TOCHA HP/LP' neste teste com dois registros alterados apresenta um pico em 2016 (máximo de 20882.292786 em 2016-05-01) e um vale em 2018 (mínimo de 153.738731 em 2018-05-01).  Vamos ver se os modelos identificam as anomalias?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Lxjj0crXN0"
      },
      "source": [
        "## Análise de Anomalias 3.1: Gráfico de Controle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GUJucRXrXN0"
      },
      "source": [
        "Portanto, vamos criar um gráfico de controle unilateral (para baixo que era o único exemplo que tinha)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jlLP5FNrXN0"
      },
      "source": [
        "def control_plot(time_series, threshold):\r\n",
        "    '''\r\n",
        "    Creates a one-sided control plot from a time series\r\n",
        "    (that is, plots threshold above the mean but not below)\r\n",
        "    Also, returns list of points that exceed the threshold\r\n",
        "    i.e., points for which the value > mean + threshold*(standard deviation)\r\n",
        "    \r\n",
        "    Args: \r\n",
        "        time_series: (pandas dataframe; index column is date in datetime format and  \r\n",
        "        column 0 is data)\r\n",
        "        threshold: z-score threshold for anomaly detection (float)\r\n",
        "\r\n",
        "    Returns: \r\n",
        "        Control plot of time_series    \r\n",
        "        anomalies: anomalies that exceed threshold (pandas dataframe)\r\n",
        "    ''' \r\n",
        "    \r\n",
        "    mean_= time_series.iloc[:,0].mean()\r\n",
        "    stdev_= time_series.iloc[:,0].std()\r\n",
        "    cutoff = mean_+threshold*stdev_\r\n",
        "    plt.figure(dpi=140)\r\n",
        "    time_series.plot(ax=plt.gca())\r\n",
        "    plt.axhline(y=mean_, color='g', linestyle='--', label='mean')\r\n",
        "    # Use threshold to plot line at threshold*stdev_ times away from the mean\r\n",
        "    plt.axhline(y=cutoff, color='r', linestyle=':', label='threshold')\r\n",
        "    plt.legend(loc='best')\r\n",
        "    plt.title('Fonte2_teste')\r\n",
        "    plt.ylabel('Emissões CO2eq')\r\n",
        "    \r\n",
        "    # Create dataframe of anomalies that exceed the cutoff\r\n",
        "    anomalies = time_series[time_series.values > cutoff]\r\n",
        "    return anomalies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xys2eyNrXN1"
      },
      "source": [
        "Defina um limite de 3 desvios padrão e plote os resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa8VqjH4rXN1"
      },
      "source": [
        "anomaly_fonte2 = control_plot(newdf_fonte2_teste, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3_fs_9ErXN1"
      },
      "source": [
        "Pelo gráfico gerado e resultado a seguir, foi detectada a anomalia superior de 20882.292786 do dia 2016-05-01. Como só temos o modelo de threshold superior,  não foi detectada a anomalias inferior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPSutgKDrXN1"
      },
      "source": [
        "print(anomaly_fonte2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu1gGOG7rXN2"
      },
      "source": [
        "### Análise de Anomalias 3.2: Soma acumulada (CUSUM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehfX0YtTrXN2"
      },
      "source": [
        "def cusum_plot(time_series, threshold):\r\n",
        "    '''\r\n",
        "    Plote as somas cumulativas alta e baixa e use-as para detecção de anomalias.\r\n",
        "     Uma anomalia é relatada se as somas cumulativas estiverem além de um determinado limite.\r\n",
        "    \r\n",
        "     Args:\r\n",
        "         time_series: (uma série temporal como pandas dataframe; a coluna de índice é date\r\n",
        "         no formato datetime e a coluna 0 é data)\r\n",
        "         threshold: limite para classificar o ponto como anomalia (float)\r\n",
        "\r\n",
        "     Devoluções:\r\n",
        "         Uma plotagem dos dados com a soma acumulada alta.\r\n",
        "         cusum_results: as somas cumulativas alta e baixa, juntamente com dados\r\n",
        "         e quaisquer anomalias acima e abaixo do limite (quadro de dados do pandas;\r\n",
        "         da função cumsum)\r\n",
        "    ''' \r\n",
        "    # Use a média e o desvio padrão de toda a série temporal\r\n",
        "     # para calcular somas cumulativas\r\n",
        "    mean_= time_series.iloc[:,0].mean()\r\n",
        "    stdev_= time_series.iloc[:,0].std()\r\n",
        "    \r\n",
        "    # definir limiar em termos de desvio padrão\r\n",
        "    cusum_results = cusum(time_series, mean_, stdev_, threshold*stdev_)\r\n",
        "    ax=time_series.plot()\r\n",
        "    ax.axhline(y=mean_, color='g', linestyle='--',label='average')\r\n",
        "    ax.axhline(y=mean_+threshold*stdev_, color='r', linestyle='--',label='High threshold')\r\n",
        "    ax.axhline(y=mean_-threshold*stdev_, color='r', linestyle='--',label='Low threshold')\r\n",
        "    # Use threshold to plot line at threshold*stdev_ times away from the mean\r\n",
        "    ax.scatter(x=cusum_results[0].index, y=cusum_results[0]['Low_Cusum'], \r\n",
        "             color='k', linestyle=':',label='Low Cusum')\r\n",
        "    ax.scatter(x=cusum_results[0].index, y=cusum_results[0]['High_Cusum'], \r\n",
        "             color='y', linestyle=':',label='High Cusum')                 \r\n",
        "    plt.legend(loc='lower right')\r\n",
        "    plt.title('Fonte 2_teste Emissions - CUSUM')\r\n",
        "    plt.ylabel('CO2 Emissions')\r\n",
        "    plt.gcf().set_size_inches(8,6)\r\n",
        "    plt.show()\r\n",
        "    return cusum_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EncmUhh5rXN2"
      },
      "source": [
        "Escolha do limiar: para o gráfico de controle, usamos 3 vezes o desvio padrão. Observe que o limite equivalente para CUSUM é * threshold * = 2, pois CUSUM inclui o * shift * (que escolhemos ser um desvio padrão) em seu cálculo da soma acumulada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV8A0Mo2rXN2"
      },
      "source": [
        "anomaly_fonte2_teste_cusum = cusum_plot(newdf_fonte2_teste, 2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzwHxoWIrXN3"
      },
      "source": [
        "Aparentemente nosso modelo detectou as duas anomalias inseridas bem como um outro registro (2017-07-01). O resultado reflete a diferença nos algoritmos de CUSUM e Tabela de Controle. A tabela de controle está procurando pontos únicos e anômalos. CUSUM é sensível a alterações no comportamento dos dados. Como resultado, sinaliza pontos como anômalos até que o comportamento da série temporal retorne ao normal.\r\n",
        "\r\n",
        "De fato, CUSUM é usado para detecção de pontos de mudança: encontrar quando a distribuição subjacente da série temporal mudou."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6y1CPu_rXN3"
      },
      "source": [
        "print(anomaly_fonte2_teste_cusum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQt5ipXwrXN3"
      },
      "source": [
        "Não consegui imprimir apenas os dados que apresentaram apenas anomalias. No gráfico da aula o professo também só teve o dado visual. Outra dificuldade não solucionada foi na plotagem do CUSUM em cima do gráfico de emissões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vgcrnhkrXN3"
      },
      "source": [
        "### Análise 3.3: modelos autorregressivos\r\n",
        "\r\n",
        "Nos dois métodos anteriores, realizamos a análise no modo offline - tínhamos todos os dados de interesse em mãos. Como resultado, ao examinar um determinado ponto, poderíamos usar o passado e o futuro (com relação a esse ponto) para calcular estatísticas como a média e o desvio padrão.\r\n",
        "\r\n",
        "Modelos autorregressivos são comumente usados para detecção de anomalias em fluxo. Para analisar séries temporais no modo de streaming - ou seja, à medida que os dados se tornam disponíveis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec4zQtv-rXN3"
      },
      "source": [
        "Como linha de base para o modelo de regressão automática, podemos verificar o que um gráfico de controle revela como anomalias. Em contraste com o exemplo da precipitação, aqui podemos ter anomalias em ambos os lados da média, portanto modificamos * control_plot * para se tornar um gráfico de controle completo de dois lados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfLhGKywrXN4"
      },
      "source": [
        "def control_plot_full(time_series, threshold):\r\n",
        "    '''\r\n",
        "    Cria um gráfico de controle frente e verso de uma série temporal\r\n",
        "     (limiar de plotagem acima e abaixo da média)\r\n",
        "     Além disso, retorna a lista de pontos que excedem o limite\r\n",
        "     ou seja, pontos para os quais o valor> média + limite * (desvio padrão)\r\n",
        "     e valor <média - limiar * (desvio padrão)\r\n",
        "    \r\n",
        "     Args:\r\n",
        "         time_series: (pandas dataframe; a coluna de índice é a data no formato datetime e\r\n",
        "         coluna 0 são dados)\r\n",
        "         threshold: limite para detecção de anomalias (float)\r\n",
        "\r\n",
        "     Devoluções:\r\n",
        "         Gráfico de controle de time_series\r\n",
        "         anomalias: anomalias que excedem o limite (pandas dataframe)\r\n",
        "    ''' \r\n",
        "    \r\n",
        "    mean_= time_series.iloc[:, 0].mean()\r\n",
        "    stdev_= time_series.iloc[:, 0].std()\r\n",
        "    time_series.plot()\r\n",
        "    plt.axhline(y=mean_, color='g', linestyle='--',label='average')\r\n",
        "    # Use threshold to plot line at threshold*stdev_ times away from the mean\r\n",
        "    plt.axhline(y=mean_+threshold*stdev_, color='r', linestyle=':', label='high threshold')\r\n",
        "    plt.axhline(y=mean_-threshold*stdev_, color='m', linestyle=':', label='low threshold')\r\n",
        "    plt.legend(loc='upper right')\r\n",
        "    plt.title('Fonte 2_teste Emissions')\r\n",
        "    plt.ylabel('CO2eq Emissions')\r\n",
        "    plt.gcf().set_size_inches(8,6)\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "    # Create dataframe of anomalies that exceed the threshold\r\n",
        "    anomaly_mask = (np.abs(time_series.values - mean_) > threshold*stdev_)\r\n",
        "    anomalies = time_series[anomaly_mask]\r\n",
        "    return anomalies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br8a5suPrXN4"
      },
      "source": [
        "control_plot_full(newdf_fonte2_teste, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCrAoaU5z4ZO"
      },
      "source": [
        "Observem que o low threshold não deveria ficar abaixo de 0. Todo dado abaixo de 0 deveria ser considerado uma anomalia, portanto o low threshold deve ser > 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD2MDtE_rXN5"
      },
      "source": [
        "Somente pelo resultado do gráfico, encontramos apenas a anomalias 2016-05-01\t20882.292786."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Xd_J5QrXN5"
      },
      "source": [
        "print(newdf_fonte2_teste.index.inferred_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6TgBhdirXN5"
      },
      "source": [
        "O print acima serviu apenas para identificar a frequência dos registros: Frequência mensal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXl3NiBqrXN5"
      },
      "source": [
        "newdf_fonte2_teste.index.freq=newdf_fonte2_teste.index.inferred_freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mfs9J7_rXN5"
      },
      "source": [
        "Para a análise a seguir, tive que alterar a ordem de 1,1,2 para 1,1,1. Não entendi muito bem o que fiz, mas assim não deu mais erro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7BYvOnNrXN5"
      },
      "source": [
        "efonte2_teste_sar=ARIMA(newdf_fonte2_teste, order=(1,1,1)).fit()\r\n",
        "\r\n",
        "efonte2_teste_sar.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ur54eFArXN6"
      },
      "source": [
        "Como no exemplo de aula, não discutiremos as estatísticas relatadas, exceto para dizer que ela inclui o desvio padrão dos resíduos (32.300), que usaremos posteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg1UKhy7rXN6"
      },
      "source": [
        "Verificamos os diagnósticos para verificar se as premissas subjacentes ao modelo são atendidas e também para obter informações adicionais sobre a qualidade do ajuste. Isso é feito usando um gráfico Q-Q (verificando se os resíduos seguem uma distribuição normal), investigando os resíduos por padrões temporais e plotando um histograma dos resíduos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbBqWFgcrXN6"
      },
      "source": [
        "# Get the predicted standard deviation. This is the 6.516 we saw earlier\r\n",
        "sigma_pred = efonte2_teste_sar.resid.std()\r\n",
        "# Calculate the standardized residuals from the (regular) residuals\r\n",
        "efonte2_teste_std_resid = efonte2_teste_sar.resid/sigma_pred\r\n",
        "\r\n",
        "plt.title('Patterns in residual')\r\n",
        "plt.plot(efonte2_teste_std_resid);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JNvSrMjrXN6"
      },
      "source": [
        "fig = plt.figure(figsize=(12,6))\r\n",
        "ax = plt.subplot(121)\r\n",
        "plt.title('Distribution of residuals')\r\n",
        "sns.distplot(efonte2_teste_std_resid.values, bins=50, ax=ax);\r\n",
        "stats.probplot(efonte2_teste_std_resid.values, dist='norm', sparams=(2.5,), plot=plt.subplot(122));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq42EgBhrXN6"
      },
      "source": [
        "Para detecção de anomalias, focamos no gráfico superior: resíduos padronizados. O residual padronizado é o residual (a diferença entre o valor observado e o valor previsto) dividido pelo desvio padrão previsto (a raiz quadrada da variação prevista mencionada acima). É uma versão mais sofisticada do z-score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4haxsr2rXN7"
      },
      "source": [
        "Uma regra prática para detectar anomalias com resíduos padronizados: anomalias são pontos para os quais a magnitude dos resíduos padronizados é maior que 4. Vamos encontrar esses pontos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd6gyY7LrXN7"
      },
      "source": [
        "# Reportar as anomalias\r\n",
        "anomaly_mask = np.abs(efonte2_teste_std_resid) > 4\r\n",
        "efonte2_teste_anomalies = efonte2_teste_std_resid[anomaly_mask]\r\n",
        "print(efonte2_teste_anomalies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qGEaJ8vrXN7"
      },
      "source": [
        "Nosso modelo encontrou apenas a anomalia de 2016-05-01."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACqrYpyaDRhA"
      },
      "source": [
        "# Questões a resolver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ms7tXhT6lXm"
      },
      "source": [
        "1) Notebook está sendo criado no colab e tenho que ficar colocando a base de dados toda vez q desconecto e conecto novamente. Qual seriam as soluçõs alternativas? \r\n",
        "  a) colocar no meu drive mas aí teria que dar acesso ao novo usuário?\r\n",
        "  b) colocar no git hub e ler de lá?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J85u26ykRSY8"
      },
      "source": [
        "2) Análise de Anomalias 1.1: Gráfico de Controle - Não consegui colocar o limite inferior, apenas o superior que foi o mesmo utilizado no exemplo de aula pelo professor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXmjtfjbV2uc"
      },
      "source": [
        "3) Análise de Anomalias 1.2: CUSUM - Não consegui analisar/plotar o scatter fora da linha 0:\r\n",
        "\r\n",
        "    ax.scatter(x=cusum_results[0].index, y=cusum_results[0]['Low_Cusum'], \r\n",
        "             color='k', linestyle=':',label='Low Cusum')\r\n",
        "    ax.scatter(x=cusum_results[0].index, y=cusum_results[0]['High_Cusum'], \r\n",
        "             color='y', linestyle=':',label='High Cusum') \r\n",
        "\r\n",
        "Não consegui printar apenas os dados com anomalias detectadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGs5ClMFXKfm"
      },
      "source": [
        "4) Análise 3.3: modelos autorregressivos\r\n",
        "\r\n",
        "Observem que o low threshold não deveria ficar abaixo de 0. Todo dado abaixo de 0 deveria ser considerado uma anomalia, portanto o low threshold deve ser > 0.\r\n",
        "\r\n",
        "Apenas alterando a magnitude dos resíduos para >2 é detectada a anomalia de 2018-05-01, no entanto ele detecta também outro ponto que não seria anômalo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxde5XO5zlNN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}